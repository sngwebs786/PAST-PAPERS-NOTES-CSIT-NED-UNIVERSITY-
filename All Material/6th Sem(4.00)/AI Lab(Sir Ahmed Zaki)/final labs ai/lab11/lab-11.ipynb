{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL3YeQhtksj0",
        "outputId": "bfb5984f-aab1-4607-8a58-14e649f542d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize,sent_tokenize"
      ],
      "metadata": {
        "id": "0UQv9OOvlFhE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"joe waited for the train. The train was late sam and marry took the bus. I looked for them\"\n",
        "print(\"\\nOriginal String\")\n",
        "print(text)\n",
        "print(\"\\nTokenize word sentence wise\")\n",
        "result=[word_tokenize(t) for t in sent_tokenize(text)]\n",
        "print(\"Read the list\")\n",
        "for s in result:\n",
        "  print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aocaEZtfliUp",
        "outputId": "15ed2683-1461-4c0c-b61f-13394c2ec26b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original String\n",
            "joe waited for the train. The train was late sam and marry took the bus. I looked for them\n",
            "\n",
            "Tokenize word sentence wise\n",
            "Read the list\n",
            "['joe', 'waited', 'for', 'the', 'train', '.']\n",
            "['The', 'train', 'was', 'late', 'sam', 'and', 'marry', 'took', 'the', 'bus', '.']\n",
            "['I', 'looked', 'for', 'them']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"joe waited for the train. The train was late sam and marry took the bus. I looked for them\"\n",
        "print(\"\\nOriginal String\")\n",
        "print(text)\n",
        "print(\"\\nlist of words\")\n",
        "print(word_tokenize(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRbqDeRomO5w",
        "outputId": "841144b1-9d22-4be1-ae08-4ec95c08b6a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original String\n",
            "joe waited for the train. The train was late sam and marry took the bus. I looked for them\n",
            "\n",
            "list of words\n",
            "['joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', 'sam', 'and', 'marry', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'them']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}